# TOC_DISCORD_BOT
# DiscordLLM

By using model quantization you can run larger llms on your device that was not possible prior. Learn more about hardware needed without model quantization here: https://www.hardware-corner.net/guides/computer-to-run-llama-ai-model/

This DiscordBot uses StableBeluga7B for this example and does not remember history as it is meant to be a one shot answer in whatever specialized prompt you would like. In the future history can be brought back or you could extend this yourself.

**LEARNED about model quantization from sentdex(code is only on huggingface)** 
##### REF: https://huggingface.co/spaces/Sentdex/StableBeluga-7B-Chat/blob/main/app.py


**MODEL QUNATIZATION**
https://huggingface.co/docs/transformers/main_classes/quantization
